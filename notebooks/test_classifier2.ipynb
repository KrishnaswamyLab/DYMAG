{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/***/***/pi/***/***/Graph_expressivity/')\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "# from src.cross_validate import eval_cv, load_config_from_yaml\n",
    "from experiments.classifier2 import PDEClassifier\n",
    "from experiments.train import train, test\n",
    "from torch_geometric.loader import DataLoader as DataListLoader\n",
    "from torch.optim import Adam\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/***/***/pi/***/***/Graph_expressivity'\n",
    "# args_w_bn = load_config_from_yaml('test_w_bn.yml')\n",
    "# args_wo_bn = load_config_from_yaml('test_wo_bn.yml')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{root_path}/data/ENZYMES\"\n",
    "result_path = f\"{root_path}/results_test/ENZYMES\"\n",
    "\n",
    "with open(f\"{data_path}/id_folds.pkl\", \"rb\") as f:\n",
    "    id_folds = pickle.load(f)\n",
    "with open(f\"{data_path}/dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "n_input = dataset[0].x.size(1)\n",
    "n_output = len(np.unique([data.y.item() for data in dataset]))\n",
    "\n",
    "batch_size = 2048\n",
    "train_idx, val_idx = id_folds[0]\n",
    "train_set = [dataset[i] for i in train_idx]\n",
    "val_set = [dataset[i] for i in val_idx]\n",
    "train_loader = DataListLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataListLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde_type = 'heat'\n",
    "time_points = 10\n",
    "time_range_start = 0\n",
    "time_range = 4\n",
    "hidden_units = 16\n",
    "num_pde_layers = 2\n",
    "num_lin_layers_between = 1\n",
    "num_lin_layers_after = 2\n",
    "p_dropout = 0.5\n",
    "skip_conn = False\n",
    "batch_norm = True\n",
    "with open(f\"{data_path}/id_folds.pkl\", \"rb\") as f:\n",
    "    id_folds = pickle.load(f)\n",
    "with open(f\"{data_path}/dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "n_input = dataset[0].x.size(1)\n",
    "n_output = len(np.unique([data.y.item() for data in dataset]))\n",
    "ts = torch.linspace(time_range_start, time_range, time_points, dtype=torch.float, device=device)\n",
    "model = PDEClassifier(\n",
    "    pde=pde_type, \n",
    "    ts=ts, \n",
    "    n_input=n_input, \n",
    "    n_hidden=hidden_units, \n",
    "    n_output=n_output, \n",
    "    device=device,\n",
    "    num_layers=num_pde_layers,\n",
    "    num_lin_layers_between_pde=num_lin_layers_between,\n",
    "    num_lin_layers_after_pde=num_lin_layers_after,\n",
    "    p_dropout=p_dropout,\n",
    "    skip_conn=skip_conn,\n",
    "    batch_norm=batch_norm\n",
    ").to(device)\n",
    "initial_state_dict = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 1.9375, Accuracy: 0.1648\n",
      "Epoch 101/1000, Loss: 1.6989, Accuracy: 0.2593\n",
      "Epoch 201/1000, Loss: 1.5729, Accuracy: 0.3463\n",
      "Epoch 301/1000, Loss: 1.4098, Accuracy: 0.4278\n",
      "Epoch 401/1000, Loss: 1.3465, Accuracy: 0.4370\n",
      "Epoch 501/1000, Loss: 1.2242, Accuracy: 0.5074\n",
      "Epoch 601/1000, Loss: 1.1543, Accuracy: 0.5222\n",
      "Epoch 701/1000, Loss: 1.0565, Accuracy: 0.5722\n",
      "Epoch 801/1000, Loss: 1.0600, Accuracy: 0.5926\n",
      "Epoch 901/1000, Loss: 1.0589, Accuracy: 0.5722\n",
      "Test accuracy: 61.67%\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = CrossEntropyLoss()\n",
    "criterion = torch.nn.NLLLoss()\n",
    "# Train the model\n",
    "train(model, train_loader, optimizer, criterion, device, num_epochs=1000)\n",
    "test(model, val_loader, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test reset parameters (should reset for a new cv fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pde_layers.0.lin_layer.weight has not been reset\n",
      "pde_layers.0.lin_layer.bias has not been reset\n",
      "pde_layers.0.bn1.weight has been reset\n",
      "pde_layers.0.bn1.bias has been reset\n",
      "pde_layers.0.bn1.running_mean has been reset\n",
      "pde_layers.0.bn1.running_var has been reset\n",
      "pde_layers.0.bn1.num_batches_tracked has been reset\n",
      "pde_layers.0.bn2.weight has been reset\n",
      "pde_layers.0.bn2.bias has been reset\n",
      "pde_layers.0.bn2.running_mean has been reset\n",
      "pde_layers.0.bn2.running_var has been reset\n",
      "pde_layers.0.bn2.num_batches_tracked has been reset\n",
      "pde_layers.1.lin_layer.weight has not been reset\n",
      "pde_layers.1.lin_layer.bias has not been reset\n",
      "pde_layers.1.bn1.weight has been reset\n",
      "pde_layers.1.bn1.bias has been reset\n",
      "pde_layers.1.bn1.running_mean has been reset\n",
      "pde_layers.1.bn1.running_var has been reset\n",
      "pde_layers.1.bn1.num_batches_tracked has been reset\n",
      "pde_layers.1.bn2.weight has been reset\n",
      "pde_layers.1.bn2.bias has been reset\n",
      "pde_layers.1.bn2.running_mean has been reset\n",
      "pde_layers.1.bn2.running_var has been reset\n",
      "pde_layers.1.bn2.num_batches_tracked has been reset\n",
      "lin_layers_after_pde.0.lin_layer.weight has not been reset\n",
      "lin_layers_after_pde.0.lin_layer.bias has not been reset\n",
      "lin_layers_after_pde.0.bn.weight has been reset\n",
      "lin_layers_after_pde.0.bn.bias has been reset\n",
      "lin_layers_after_pde.0.bn.running_mean has been reset\n",
      "lin_layers_after_pde.0.bn.running_var has been reset\n",
      "lin_layers_after_pde.0.bn.num_batches_tracked has been reset\n",
      "lin_layers_after_pde.1.lin_layer.weight has not been reset\n",
      "lin_layers_after_pde.1.lin_layer.bias has not been reset\n",
      "lin_layers_after_pde.1.bn.weight has been reset\n",
      "lin_layers_after_pde.1.bn.bias has been reset\n",
      "lin_layers_after_pde.1.bn.running_mean has been reset\n",
      "lin_layers_after_pde.1.bn.running_var has been reset\n",
      "lin_layers_after_pde.1.bn.num_batches_tracked has been reset\n",
      "classifier.0.weight has not been reset\n",
      "classifier.0.bias has not been reset\n"
     ]
    }
   ],
   "source": [
    "middle_state_dict = copy.deepcopy(model.state_dict())\n",
    "model.reset_parameters()\n",
    "reset_state_dict = model.state_dict()\n",
    "# check if the parameters have been reset\n",
    "for layer in initial_state_dict:\n",
    "    if not torch.all(torch.eq(initial_state_dict[layer], reset_state_dict[layer])):\n",
    "        print(f\"{layer} has not been reset\")\n",
    "    else:\n",
    "        print(f\"{layer} has been reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pde_layers.0.lin_layer.weight not eql\n",
      "pde_layers.0.lin_layer.bias not eql\n",
      "pde_layers.0.bn1.weight not eql\n",
      "pde_layers.0.bn1.bias not eql\n",
      "pde_layers.0.bn1.running_mean not eql\n",
      "pde_layers.0.bn1.running_var not eql\n",
      "pde_layers.0.bn1.num_batches_tracked not eql\n",
      "pde_layers.0.bn2.weight not eql\n",
      "pde_layers.0.bn2.bias not eql\n",
      "pde_layers.0.bn2.running_mean not eql\n",
      "pde_layers.0.bn2.running_var not eql\n",
      "pde_layers.0.bn2.num_batches_tracked not eql\n",
      "pde_layers.1.lin_layer.weight not eql\n",
      "pde_layers.1.lin_layer.bias not eql\n",
      "pde_layers.1.bn1.weight not eql\n",
      "pde_layers.1.bn1.bias not eql\n",
      "pde_layers.1.bn1.running_mean not eql\n",
      "pde_layers.1.bn1.running_var not eql\n",
      "pde_layers.1.bn1.num_batches_tracked not eql\n",
      "pde_layers.1.bn2.weight not eql\n",
      "pde_layers.1.bn2.bias not eql\n",
      "pde_layers.1.bn2.running_mean not eql\n",
      "pde_layers.1.bn2.running_var not eql\n",
      "pde_layers.1.bn2.num_batches_tracked not eql\n",
      "lin_layers_after_pde.0.lin_layer.weight not eql\n",
      "lin_layers_after_pde.0.lin_layer.bias not eql\n",
      "lin_layers_after_pde.0.bn.weight not eql\n",
      "lin_layers_after_pde.0.bn.bias not eql\n",
      "lin_layers_after_pde.0.bn.running_mean not eql\n",
      "lin_layers_after_pde.0.bn.running_var not eql\n",
      "lin_layers_after_pde.0.bn.num_batches_tracked not eql\n",
      "lin_layers_after_pde.1.lin_layer.weight not eql\n",
      "lin_layers_after_pde.1.lin_layer.bias not eql\n",
      "lin_layers_after_pde.1.bn.weight not eql\n",
      "lin_layers_after_pde.1.bn.bias not eql\n",
      "lin_layers_after_pde.1.bn.running_mean not eql\n",
      "lin_layers_after_pde.1.bn.running_var not eql\n",
      "lin_layers_after_pde.1.bn.num_batches_tracked not eql\n",
      "classifier.0.weight not eql\n",
      "classifier.0.bias not eql\n"
     ]
    }
   ],
   "source": [
    "for layer in initial_state_dict:\n",
    "    if not torch.all(torch.eq(middle_state_dict[layer], reset_state_dict[layer])):\n",
    "        print(f\"{layer} not eql\")\n",
    "    else:\n",
    "        print(f\"{layer} eql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PDEClassifier(\n",
    "    pde='wave', \n",
    "    ts=ts, \n",
    "    n_input=n_input, \n",
    "    n_hidden=hidden_units, \n",
    "    n_output=n_output, \n",
    "    device=device,\n",
    "    num_layers=num_pde_layers,\n",
    "    num_lin_layers_between_pde=num_lin_layers_between,\n",
    "    num_lin_layers_after_pde=num_lin_layers_after,\n",
    "    p_dropout=p_dropout,\n",
    "    skip_conn=skip_conn,\n",
    "    batch_norm=False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 5.1978, Accuracy: 0.1444\n",
      "Epoch 101/1000, Loss: 1.7534, Accuracy: 0.1907\n",
      "Epoch 201/1000, Loss: 1.7516, Accuracy: 0.2000\n",
      "Epoch 301/1000, Loss: 1.7527, Accuracy: 0.2259\n",
      "Epoch 401/1000, Loss: 1.7083, Accuracy: 0.2685\n",
      "Epoch 501/1000, Loss: 1.6975, Accuracy: 0.2352\n",
      "Epoch 601/1000, Loss: 1.6881, Accuracy: 0.2574\n",
      "Epoch 701/1000, Loss: 1.6512, Accuracy: 0.2889\n",
      "Epoch 801/1000, Loss: 1.6412, Accuracy: 0.3056\n",
      "Epoch 901/1000, Loss: 1.6392, Accuracy: 0.3204\n",
      "Test accuracy: 25.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = CrossEntropyLoss()\n",
    "criterion = torch.nn.NLLLoss()\n",
    "# Train the model\n",
    "train(model, train_loader, optimizer, criterion, device, num_epochs=1000)\n",
    "test(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
