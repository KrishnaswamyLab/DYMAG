{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree, get_laplacian, from_networkx, from_scipy_sparse_matrix\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index_to_adjacency(edge_index, edge_weight, num_nodes):\n",
    "    adjacency_matrix = torch.zeros((num_nodes, num_nodes))\n",
    "    adjacency_matrix[edge_index[0], edge_index[1]] = edge_weight\n",
    "    adjacency_matrix[edge_index[1], edge_index[0]] = edge_weight  # For undirected graph\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "G.add_nodes_from([0, 1, 2, 3, 4])\n",
    "\n",
    "# Add weighted edges to the graph\n",
    "G.add_weighted_edges_from([(0, 1, 0.5), (1, 2, 0.7), (1, 3, 0.6), (2, 3, 0.9), (3, 4, 0.2)])\n",
    "\n",
    "# Visualize the graph with labels\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_size=800, node_color='lightblue')\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "laplacian_mat = nx.normalized_laplacian_matrix(G).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphinfo = from_networkx(G)\n",
    "edge_index, edge_weight = graphinfo.edge_index, graphinfo.weight\n",
    "laplacian_edge_index, laplacian_edge_weight = get_laplacian(edge_index, edge_weight, normalization='sym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapl = edge_index_to_adjacency(laplacian_edge_index, laplacian_edge_weight, graphinfo.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.5270,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.5270,  1.0000, -0.4125, -0.3430,  0.0000],\n",
       "        [ 0.0000, -0.4125,  1.0000, -0.5457,  0.0000],\n",
       "        [ 0.0000, -0.3430, -0.5457,  1.0000, -0.3430],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.3430,  1.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.52704628,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.52704628,  1.        , -0.41247896, -0.34299717,  0.        ],\n",
       "       [ 0.        , -0.41247896,  1.        , -0.54570516,  0.        ],\n",
       "       [ 0.        , -0.34299717, -0.54570516,  1.        , -0.34299717],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.34299717,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.22044605e-16, -1.34768038e-08,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.34768038e-08, -1.11022302e-16, -2.09222284e-09,\n",
       "        -6.75085321e-09,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -3.18945452e-08,  0.00000000e+00,\n",
       "        -1.66947557e-08,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -6.75085321e-09, -1.66947557e-08,\n",
       "         0.00000000e+00,  2.30514691e-08],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.30514691e-08,  2.22044605e-16]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mat.toarray() - lapl.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test matrix-vector multiplication via message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatVecMult(MessagePassing):\n",
    "    \"\"\"\n",
    "    Chebyshev polynomials as a custom message passing layer.\n",
    "    need another layer to do the aggregation.\n",
    "    the normalized laplacian computation is handled as a normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, edge_weight):\n",
    "        \"\"\"computes the graph laplacian, ?as well as the basis matrix for the Chebyshev polynomials.\n",
    "\n",
    "        Args:\n",
    "            edge_index (tensor): shape (2, E). E is number of edges.\n",
    "            edge_weight (tensor, optional): shape (E, ).\n",
    "        \"\"\"\n",
    "        super().__init__(aggr=\"add\", node_dim=-3)  # \"Add\" aggregation.\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        ## using symmetrically normalized laplacian so that the eigenvalues are within [0, 2]\n",
    "        ## see https://math.stackexchange.com/questions/2511544/largest-eigenvalue-of-a-normalized-graph-laplacian\n",
    "        self.laplacian_edge_index, self.laplacian_edge_weight = get_laplacian(\n",
    "            self.edge_index, self.edge_weight, normalization='sym')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (tensor): shape (n, *, *). n is number of nodes.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            tensor: shape (n, *, *).\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index=self.laplacian_edge_index, x=x, edge_weight=self.laplacian_edge_weight)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return self.laplacian_edge_weight.view(-1, 1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2426,  0.1426,  0.2026, -0.2063, -0.0158])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lapl @ x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2426,  0.1426,  0.2026, -0.2063, -0.0158])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multer = MatVecMult(edge_index, edge_weight)\n",
    "multer(x).squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cheby coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cheby_coefs(func, degree, N=1000):\n",
    "    \"\"\"\n",
    "    get the Chebyshev polynomial coefficients of the function.\n",
    "\n",
    "    Args:\n",
    "        func (function): the function to be integrated.\n",
    "        degree (int): the degree of the Chebyshev polynomials. (the min power is 0, the max power is degree - 1)\n",
    "        a (float): the lower bound of the integration.\n",
    "        b (float): the upper bound of the integration.\n",
    "        N (int, optional): the number of points to be used in the integration. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (k, ). the coefficients of the Chebyshev polynomials.\n",
    "    \n",
    "    Note:\n",
    "        see https://en.wikipedia.org/wiki/Chebyshev_polynomials#Orthogonality for the formula for computing the coefficients.\n",
    "    \"\"\"\n",
    "    ks = torch.arange(N)\n",
    "    xks = torch.cos(torch.pi * (ks + 0.5) / (N)) + 1 ## reparameterize from [-1, 1] to [0, 2]\n",
    "    ns = torch.arange(degree).unsqueeze(-1)\n",
    "    Tn_xks = torch.cos(ns * torch.pi * (ks + 0.5) / (N)) ## shape (degree, N)\n",
    "    func_xks = func(xks) ## shape (N,)\n",
    "    coefs = (2 * Tn_xks * func_xks).mean(axis=1) ## shape (degree,)\n",
    "    coefs[0] /= 2\n",
    "    # return coefs.squeeze() ## TODO test shape of coefs before squeeze.\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_coef(func, alpha, deg, n=1000):\n",
    "    \"\"\"\n",
    "    fit the coefficients of the chebyshev polynomials\n",
    "\n",
    "    Args:\n",
    "        func: the function to fit\n",
    "        alpha: the domain of func is [0, 2*alpha]\n",
    "        deg: the degree of the polynomial\n",
    "        n: the number of points to sample\n",
    "\n",
    "    Returns:\n",
    "        the coefficients of the chebyshev polynomials\n",
    "    \"\"\"    \n",
    "    thetas = torch.linspace(0, torch.pi, n).reshape(1, -1)\n",
    "    ks = torch.arange(deg).reshape(-1, 1)\n",
    "    cs = (torch.cos(ks * thetas) * func(alpha * (torch.cos(thetas) + 1))).mean(axis=1) * 2\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: np.exp(-3 * x)\n",
    "coefs1 = get_cheby_coefs(func, degree=10)\n",
    "coefs2 = fit_coef(func, alpha=1., deg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4300e-01, -3.9365e-01,  2.2357e-01, -9.5567e-02,  3.2432e-02,\n",
       "        -9.0819e-03,  2.1591e-03, -4.4543e-04,  8.1080e-05, -1.3185e-05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4865, -0.3943,  0.2243, -0.0965,  0.0334, -0.0101,  0.0032, -0.0014,\n",
       "         0.0011, -0.0010])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test cheby eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChebyLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Chebyshev polynomials as a custom message passing layer.\n",
    "    need another layer to do the aggregation.\n",
    "    the normalized laplacian computation is handled as a normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, edge_weight):\n",
    "        \"\"\"computes the graph laplacian, ?as well as the basis matrix for the Chebyshev polynomials.\n",
    "\n",
    "        Args:\n",
    "            edge_index (tensor): shape (2, E). E is number of edges.\n",
    "            edge_weight (tensor, optional): shape (E, ).\n",
    "        \"\"\"\n",
    "        super().__init__(aggr=\"add\", node_dim=-3)  # \"Add\" aggregation.\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        ## using symmetrically normalized laplacian so that the eigenvalues are within [0, 2]\n",
    "        ## see https://math.stackexchange.com/questions/2511544/largest-eigenvalue-of-a-normalized-graph-laplacian\n",
    "        self.laplacian_edge_index, self.laplacian_edge_weight = get_laplacian(\n",
    "            self.edge_index, self.edge_weight, normalization='sym')\n",
    "\n",
    "    def forward(self, x, coefs, t=None):\n",
    "        \"\"\"Evaluate the chebyshev polynomials through recursive message passing.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): shape (n, *, *). n is number of nodes.\n",
    "            coefs (tensor): shape (k). k is the degree of the chebyshev polynomials.\n",
    "            t (tensor): shape (T, ). T is the number of time points. t is the sample times.\n",
    "\n",
    "        Returns:\n",
    "            tensor: shape (n, *, *).\n",
    "        \"\"\"\n",
    "        k = len(coefs)\n",
    "        assert  k > 2\n",
    "        T0 = x\n",
    "        out = coefs[0] * T0\n",
    "        T1 = self.propagate(edge_index=self.laplacian_edge_index, x=x, edge_weight=self.laplacian_edge_weight)\n",
    "        out += coefs[1] * T1\n",
    "\n",
    "        for i in range(2, k):\n",
    "            T2 = 2 * self.propagate(edge_index=self.laplacian_edge_index, x=T1, edge_weight=self.laplacian_edge_weight) - T0\n",
    "            out += coefs[i] * T2\n",
    "            T0, T1 = T1, T2\n",
    "\n",
    "        return out\n",
    "        # return self.propagate(edge_index=self.laplacian_edge_index, x=x, edge_weight=self.laplacian_edge_weight)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return self.laplacian_edge_weight.view(-1, 1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out - x ## reparameterize lambda to range (-1, 1) (L_tilde = L - I, so L_tilde x = L x - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheb = ChebyLayer(edge_index, edge_weight)\n",
    "y1 = cheb(x, coefs1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, V = np.linalg.eigh(laplacian_mat.toarray())\n",
    "M2 = V @ np.diag(np.exp(- 3 * lam)) @ V.T \n",
    "y2 = M2 @ x.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = torch.linalg.matrix_exp(-3 * torch.tensor(laplacian_mat.toarray()).float())\n",
    "y3 = M3 @ x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3475, 0.6768, 0.6485, 0.6639, 0.2236])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34751272, 0.67683191, 0.64850767, 0.66386158, 0.22359572])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3475, 0.6768, 0.6485, 0.6639, 0.2236])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.8545e-07, -8.9407e-07, -9.5367e-07, -1.3113e-06, -5.8115e-07])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 - y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Multiple time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChebyLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Chebyshev polynomials as a custom message passing layer.\n",
    "    need another layer to do the aggregation.\n",
    "    the normalized laplacian computation is handled as a normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, edge_weight):\n",
    "        \"\"\"computes the graph laplacian, ?as well as the basis matrix for the Chebyshev polynomials.\n",
    "\n",
    "        Args:\n",
    "            edge_index (tensor): shape (2, E). E is number of edges.\n",
    "            edge_weight (tensor, optional): shape (E, ).\n",
    "        \"\"\"\n",
    "        super().__init__(aggr=\"add\", node_dim=-3)  # \"Add\" aggregation.\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        ## using symmetrically normalized laplacian so that the eigenvalues are within [0, 2]\n",
    "        ## see https://math.stackexchange.com/questions/2511544/largest-eigenvalue-of-a-normalized-graph-laplacian\n",
    "        self.laplacian_edge_index, self.laplacian_edge_weight = get_laplacian(\n",
    "            self.edge_index, self.edge_weight, normalization='sym')\n",
    "\n",
    "    def forward(self, x, coefs):\n",
    "        \"\"\"Evaluate the chebyshev polynomials through recursive message passing.\n",
    "        coefs is 2 dimentional with the first dimension to be time points.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): shape (n, *, *). n is number of nodes.\n",
    "            coefs (tensor): shape (T, k). \n",
    "                k is the degree of the chebyshev polynomials.\n",
    "                T is the number of time points. t is the sample times.\n",
    "\n",
    "        Returns:\n",
    "            tensor: shape (T, n, *, *).\n",
    "        \"\"\"\n",
    "        k = coefs.size(1)\n",
    "        assert  k > 2\n",
    "        T0 = x\n",
    "        out = coefs[:, 0].view(-1, 1, 1, 1) * T0\n",
    "        T1 = self.propagate(edge_index=self.laplacian_edge_index, x=x, edge_weight=self.laplacian_edge_weight)\n",
    "        out += coefs[:, 1].view(-1, 1, 1, 1) * T1\n",
    "\n",
    "        for i in range(2, k):\n",
    "            T2 = 2 * self.propagate(edge_index=self.laplacian_edge_index, x=T1, edge_weight=self.laplacian_edge_weight) - T0\n",
    "            out += coefs[:, i].view(-1, 1, 1, 1) * T2\n",
    "            T0, T1 = T1, T2\n",
    "\n",
    "        return out\n",
    "        # return self.propagate(edge_index=self.laplacian_edge_index, x=x, edge_weight=self.laplacian_edge_weight)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return self.laplacian_edge_weight.view(-1, 1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out - x ## reparameterize lambda to range (-1, 1) (L_tilde = L - I, so L_tilde x = L x - x)\n",
    "    \n",
    "def get_cheby_coefs(func, ts, degree, N=1000):\n",
    "    \"\"\"\n",
    "    get the Chebyshev polynomial coefficients of the function.\n",
    "\n",
    "    Args:\n",
    "        func (function): the function to be integrated.\n",
    "            f(t, lam) has two parameters:\n",
    "            t is the time point, and lam is the eigenvalue of the laplacian matrix\n",
    "        ts (tensor): shape (T, ). the sample time points.\n",
    "        degree (int): the degree of the Chebyshev polynomials. (the min power is 0, the max power is degree - 1)\n",
    "        N (int, optional): the number of points to be used in the integration. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (T, k). the coefficients of the Chebyshev polynomials.\n",
    "    \n",
    "    Note:\n",
    "        see https://en.wikipedia.org/wiki/Chebyshev_polynomials#Orthogonality for the formula for computing the coefficients.\n",
    "    \"\"\"\n",
    "    ks = torch.arange(N)\n",
    "    xks = torch.cos(torch.pi * (ks + 0.5) / (N)) + 1 ## reparameterize from [-1, 1] to [0, 2]\n",
    "    ns = torch.arange(degree).unsqueeze(-1)\n",
    "    Tn_xks = torch.cos(ns * torch.pi * (ks + 0.5) / (N)) ## shape (degree, N)\n",
    "    func_xks = func(ts, xks) ## shape (T, N)\n",
    "    coefs = (2 * Tn_xks.unsqueeze(0) * func_xks.unsqueeze(1)).mean(axis=-1) ## shape (T, degree)\n",
    "    coefs[:, 0] /= 2\n",
    "    return coefs\n",
    "\n",
    "def heat_eqn_oper(t, lam):\n",
    "    \"\"\"\n",
    "    the function of the heat equation solution.\n",
    "\n",
    "    Args:\n",
    "        t (tensor): shape (T, ). the time points.\n",
    "        lam (tensor): shape (N, ). the sampled points of eigenvalues of the laplacian matrix.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (T, N). the wave equation solution result for each time t and each sample point of the eigenvalues.\n",
    "    \"\"\"\n",
    "    return torch.exp(- t.view(-1, 1) * lam)\n",
    "\n",
    "def wave_eqn_oper_x(t, lam):\n",
    "    \"\"\"\n",
    "    the function for computing the wave equation solution's operator on x (initial position) cos(sqrt(lam) * t)\n",
    "\n",
    "    Args:\n",
    "        t (tensor): shape (T, ). the time points.\n",
    "        lam (tensor): shape (N, ). the sampled points of eigenvalues of the laplacian matrix.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (T, N). the wave equation solution result for each time t and each sample point of the eigenvalues.\n",
    "    \"\"\"\n",
    "    lamsqrt = torch.sqrt(lam)\n",
    "    tlamsqrt = t.view(-1, 1) * lamsqrt\n",
    "    oper_x_res = torch.cos(tlamsqrt)\n",
    "    return oper_x_res\n",
    "\n",
    "def wave_eqn_oper_y(t, lam):\n",
    "    \"\"\"\n",
    "    the function for computing the wave equation solution's operator on y (initial speed) sin(sqrt(lam) * t) / sqrt(lam)\n",
    "    Note the t term is not needed for lam_0=0, because 1 equals to the limit of sin(a)/a at 0.\n",
    "\n",
    "    Args:\n",
    "        t (tensor): shape (T, ). the time points.\n",
    "        lam (tensor): shape (N, ). the sampled points of eigenvalues of the laplacian matrix.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (T, N). the wave equation solution result for each time t and each sample point of the eigenvalues.\n",
    "    \"\"\"\n",
    "    lamsqrt = torch.sqrt(lam)\n",
    "    tlamsqrt = t.view(-1, 1) * lamsqrt\n",
    "    oper_y_res = torch.sin(tlamsqrt) / lamsqrt\n",
    "    return oper_y_res\n",
    "\n",
    "def get_cheby_coefs_heat(ts, degree, N=1000):\n",
    "    \"\"\"\n",
    "    get the Chebyshev polynomial coefficients of the heat equation.\n",
    "\n",
    "    Args:\n",
    "        ts (tensor): shape (T, ). the sample time points.\n",
    "        degree (int): the degree of the Chebyshev polynomials. (the min power is 0, the max power is degree - 1)\n",
    "        N (int, optional): the number of points to be used in the integration. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        tensor: shape (T, k). the coefficients of the Chebyshev polynomials.\n",
    "    \"\"\"\n",
    "    return get_cheby_coefs(heat_eqn_oper, ts, degree, N=N)\n",
    "\n",
    "def get_cheby_coefs_wave(ts, degree, N=1000):\n",
    "    \"\"\"\n",
    "    get the Chebyshev polynomial coefficients of the wave equation.\n",
    "\n",
    "    Args:\n",
    "        ts (tensor): shape (T, ). the sample time points.\n",
    "        degree (int): the degree of the Chebyshev polynomials. (the min power is 0, the max power is degree - 1)\n",
    "        N (int, optional): the number of points to be used in the integration. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        tuple: the coefficients of the Chebyshev polynomials.\n",
    "            the first element is the coefficients of the wave equation for x. shape (T, k)\n",
    "            the second element is the coefficients of the wave equation for y. shape (T, k)\n",
    "    \n",
    "    \"\"\"\n",
    "    return get_cheby_coefs(wave_eqn_oper_x, ts, degree, N=N), get_cheby_coefs(wave_eqn_oper_y, ts, degree, N=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.arange(6).float()\n",
    "coefs_ts = get_cheby_coefs_heat(ts, degree=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -5.5909e-08,  4.8041e-08, -3.4571e-09,  5.9605e-08,\n",
       "         -8.1897e-08,  9.4175e-09, -1.2255e-07,  4.8637e-08, -7.2718e-09],\n",
       "        [ 4.6576e-01, -4.1582e-01,  9.9878e-02, -1.6311e-02,  2.0139e-03,\n",
       "         -1.9982e-04,  1.6554e-05, -1.3008e-06,  1.2726e-07, -8.8811e-09],\n",
       "        [ 3.0851e-01, -4.3054e-01,  1.8648e-01, -5.7582e-02,  1.3731e-02,\n",
       "         -2.6596e-03,  4.3313e-04, -6.0928e-05,  7.5526e-06, -8.2606e-07],\n",
       "        [ 2.4300e-01, -3.9365e-01,  2.2357e-01, -9.5567e-02,  3.2432e-02,\n",
       "         -9.0819e-03,  2.1591e-03, -4.4543e-04,  8.1077e-05, -1.3182e-05],\n",
       "        [ 2.0700e-01, -3.5750e-01,  2.3525e-01, -1.2225e-01,  5.1880e-02,\n",
       "         -1.8489e-02,  5.6582e-03, -1.5141e-03,  3.5940e-04, -7.6569e-05],\n",
       "        [ 1.8354e-01, -3.2794e-01,  2.3590e-01, -1.3922e-01,  6.8838e-02,\n",
       "         -2.9081e-02,  1.0677e-02, -3.4565e-03,  9.9884e-04, -2.6030e-04]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4300e-01, -3.9365e-01,  2.2357e-01, -9.5567e-02,  3.2432e-02,\n",
       "        -9.0819e-03,  2.1591e-03, -4.4543e-04,  8.1080e-05, -1.3185e-05])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4300e-01, -3.9365e-01,  2.2357e-01, -9.5567e-02,  3.2432e-02,\n",
       "        -9.0819e-03,  2.1591e-03, -4.4543e-04,  8.1077e-05, -1.3182e-05])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_ts[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebs = ChebyLayer(edge_index, edge_weight)\n",
    "yts = chebs(x, coefs_ts).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1516, 0.7480, 0.8134, 0.5539, 0.1741],\n",
       "        [0.2894, 0.6834, 0.6970, 0.6500, 0.1991],\n",
       "        [0.3322, 0.6759, 0.6608, 0.6637, 0.2164],\n",
       "        [0.3475, 0.6768, 0.6485, 0.6639, 0.2236],\n",
       "        [0.3536, 0.6782, 0.6440, 0.6627, 0.2260],\n",
       "        [0.3562, 0.6790, 0.6423, 0.6618, 0.2267]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1516, 0.7480, 0.8134, 0.5539, 0.1741])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3475, 0.6768, 0.6485, 0.6639, 0.2236])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3475, 0.6768, 0.6485, 0.6639, 0.2236])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yts[3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ChebyPolyLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChebyPolyLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Chebyshev polynomials as a custom message passing layer.\n",
    "    Pass edge_index and edge_weight to the forward method.\n",
    "    \"\"\"\n",
    "    def __init__(self, coefs=None):\n",
    "        \"\"\"\n",
    "        the coefs is fixed for the layer (which is determined by the equation as well as the sampling points)\n",
    "        can make more flexible by passing time points to forward method. computing the coefficients should'nt be slow.\n",
    "        Args:\n",
    "            coefs (tensor): shape (T, k). \n",
    "                k is the degree of the chebyshev polynomials.\n",
    "                T is the number of time points. t is the sample times.\n",
    "        \"\"\"\n",
    "        super().__init__(aggr=\"add\", node_dim=-3)  # \"Add\" aggregation.\n",
    "        self.coefs = coefs\n",
    "\n",
    "    def forward(self, edge_index, edge_weight, x, coefs=None):\n",
    "        \"\"\"Evaluate the chebyshev polynomials through recursive message passing.\n",
    "        coefs is 2 dimentional with the first dimension to be time points.\n",
    "\n",
    "        Args:\n",
    "            edge_index (tensor): shape (2, E). E is number of edges.\n",
    "            edge_weight (tensor, optional): shape (E, ).\n",
    "            x (tensor): shape (n, *, *). n is number of nodes.\n",
    "            coefs (tensor): shape (T, k). \n",
    "                k is the degree of the chebyshev polynomials.\n",
    "                T is the number of time points. t is the sample times.\n",
    "\n",
    "        Returns:\n",
    "            tensor: shape (T, n, *, *).\n",
    "        \"\"\"\n",
    "        if coefs is None: coefs = self.coefs\n",
    "        assert coefs is not None\n",
    "        k = coefs.size(1)\n",
    "        assert  k > 2\n",
    "        ## using symmetrically normalized laplacian so that the eigenvalues are within [0, 2]\n",
    "        ## see https://math.stackexchange.com/questions/2511544/largest-eigenvalue-of-a-normalized-graph-laplacian\n",
    "        laplacian_edge_index, laplacian_edge_weight = get_laplacian(\n",
    "            edge_index, edge_weight, normalization='sym')\n",
    "        T0 = x\n",
    "        out = coefs[:, 0].view(-1, 1, 1, 1) * T0\n",
    "        T1 = self.propagate(edge_index=laplacian_edge_index, x=x, edge_weight=laplacian_edge_weight)\n",
    "        out += coefs[:, 1].view(-1, 1, 1, 1) * T1\n",
    "\n",
    "        for i in range(2, k):\n",
    "            T2 = 2 * self.propagate(edge_index=laplacian_edge_index, x=T1, edge_weight=laplacian_edge_weight) - T0\n",
    "            out += coefs[:, i].view(-1, 1, 1, 1) * T2\n",
    "            T0, T1 = T1, T2\n",
    "\n",
    "        return out\n",
    "        # return self.propagate(edge_index=laplacian_edge_index, x=x, edge_weight=laplacian_edge_weight)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        \"\"\"\n",
    "        edge_weight is the edge weight of the graph laplacian.\n",
    "        \"\"\"\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return edge_weight.view(-1, 1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out - x ## reparameterize lambda to range (-1, 1) (L_tilde = L - I, so L_tilde x = L x - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cpl = ChebyPolyLayer(coefs_ts)\n",
    "ycpl1 = cpl(edge_index, edge_weight, x).squeeze()\n",
    "cpl2 = ChebyPolyLayer()\n",
    "ycpl2 = cpl2(edge_index, edge_weight, x, coefs_ts).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(ycpl1, ycpl2))\n",
    "print(torch.allclose(ycpl1, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test x with shape (n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChebyPolyLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Chebyshev polynomials as a custom message passing layer.\n",
    "    Pass edge_index and edge_weight to the forward method.\n",
    "    \"\"\"\n",
    "    def __init__(self, coefs=None):\n",
    "        \"\"\"\n",
    "        the coefs is fixed for the layer (which is determined by the equation as well as the sampling points)\n",
    "        can make more flexible by passing time points to forward method. computing the coefficients should'nt be slow.\n",
    "        Args:\n",
    "            coefs (tensor): shape (T, k). \n",
    "                k is the degree of the chebyshev polynomials.\n",
    "                T is the number of time points. t is the sample times.\n",
    "        \"\"\"\n",
    "        super().__init__(aggr=\"add\", node_dim=-2)  # \"Add\" aggregation.\n",
    "        self.coefs = coefs\n",
    "\n",
    "    def forward(self, edge_index, edge_weight, x, coefs=None):\n",
    "        \"\"\"Evaluate the chebyshev polynomials through recursive message passing.\n",
    "        coefs is 2 dimentional with the first dimension to be time points.\n",
    "\n",
    "        Args:\n",
    "            edge_index (tensor): shape (2, E). E is number of edges.\n",
    "            edge_weight (tensor, optional): shape (E, ).\n",
    "            x (tensor): shape (n, m). n is number of nodes. m is number of features.\n",
    "            coefs (tensor): shape (T, k). defaults to None (use the coef specified at input).\n",
    "                k is the degree of the chebyshev polynomials.\n",
    "                T is the number of time points. t is the sample times.\n",
    "\n",
    "        Returns:\n",
    "            tensor: shape (T, n, m).\n",
    "        \"\"\"\n",
    "        if coefs is None: coefs = self.coefs\n",
    "        assert coefs is not None\n",
    "        k = coefs.size(1)\n",
    "        assert  k > 2\n",
    "        ## using symmetrically normalized laplacian so that the eigenvalues are within [0, 2]\n",
    "        ## see https://math.stackexchange.com/questions/2511544/largest-eigenvalue-of-a-normalized-graph-laplacian\n",
    "        laplacian_edge_index, laplacian_edge_weight = get_laplacian(\n",
    "            edge_index, edge_weight, normalization='sym')\n",
    "        T0 = x\n",
    "        out = coefs[:, 0].view(-1, 1, 1) * T0\n",
    "        T1 = self.propagate(edge_index=laplacian_edge_index, x=x, edge_weight=laplacian_edge_weight)\n",
    "        out += coefs[:, 1].view(-1, 1, 1) * T1\n",
    "\n",
    "        for i in range(2, k):\n",
    "            T2 = 2 * self.propagate(edge_index=laplacian_edge_index, x=T1, edge_weight=laplacian_edge_weight) - T0\n",
    "            out += coefs[:, i].view(-1, 1, 1) * T2\n",
    "            T0, T1 = T1, T2\n",
    "\n",
    "        return out\n",
    "        # return self.propagate(edge_index=laplacian_edge_index, x=x, edge_weight=laplacian_edge_weight)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        \"\"\"\n",
    "        edge_weight is the edge weight of the graph laplacian.\n",
    "        \"\"\"\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out - x ## reparameterize lambda to range (-1, 1) (L_tilde = L - I, so L_tilde x = L x - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl = ChebyPolyLayer(coefs_ts)\n",
    "ycpl3 = cpl(edge_index, edge_weight, x).squeeze()\n",
    "cpl2 = ChebyPolyLayer()\n",
    "ycpl4 = cpl2(edge_index, edge_weight, x, coefs_ts).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(ycpl1, ycpl3))\n",
    "print(torch.allclose(ycpl2, ycpl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "cpl = ChebyPolyLayer(coefs_ts)\n",
    "y_pred = cpl(edge_index, edge_weight, x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/***/***/.conda_envs/pyg/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched x tensor:\n",
      " tensor([[0.3960, 0.9554, 0.3522],\n",
      "        [0.6367, 0.1058, 0.3494],\n",
      "        [0.5748, 0.4182, 0.9883],\n",
      "        [0.2120, 0.0149, 0.4592],\n",
      "        [0.5234, 0.1553, 0.5321],\n",
      "        [0.3960, 0.9554, 0.3522],\n",
      "        [0.6367, 0.1058, 0.3494],\n",
      "        [0.5748, 0.4182, 0.9883],\n",
      "        [0.2120, 0.0149, 0.4592],\n",
      "        [0.5234, 0.1553, 0.5321]])\n",
      "Batched edge_index tensor:\n",
      " tensor([[0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 8, 8, 8, 9],\n",
      "        [1, 0, 2, 3, 1, 3, 1, 2, 4, 3, 6, 5, 7, 8, 6, 8, 6, 7, 9, 8]])\n",
      "Batch vector:\n",
      " tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "x = torch.rand(5, 3)\n",
    "# Create some example graphs\n",
    "graph1 = Data(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "graph2 = Data(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "\n",
    "# Create a list of Data objects\n",
    "data_list = [graph1, graph2]\n",
    "\n",
    "# Create a DataLoader with the list of Data objects and a specified batch size\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "\n",
    "# Iterate through the DataLoader to get batches of graphs\n",
    "for batch in loader:\n",
    "    print(\"Batched x tensor:\\n\", batch.x)\n",
    "    print(\"Batched edge_index tensor:\\n\", batch.edge_index)\n",
    "    print(\"Batch vector:\\n\", batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3960, 0.9554, 0.3522],\n",
       "         [0.6367, 0.1058, 0.3494],\n",
       "         [0.5748, 0.4182, 0.9883],\n",
       "         [0.2120, 0.0149, 0.4592],\n",
       "         [0.5234, 0.1553, 0.5321],\n",
       "         [0.3960, 0.9554, 0.3522],\n",
       "         [0.6367, 0.1058, 0.3494],\n",
       "         [0.5748, 0.4182, 0.9883],\n",
       "         [0.2120, 0.0149, 0.4592],\n",
       "         [0.5234, 0.1553, 0.5321]],\n",
       "\n",
       "        [[0.3434, 0.4475, 0.2947],\n",
       "         [0.5744, 0.3527, 0.5607],\n",
       "         [0.5000, 0.2761, 0.6943],\n",
       "         [0.4619, 0.1976, 0.6302],\n",
       "         [0.2766, 0.0868, 0.3223],\n",
       "         [0.3434, 0.4475, 0.2947],\n",
       "         [0.5744, 0.3527, 0.5607],\n",
       "         [0.5000, 0.2761, 0.6943],\n",
       "         [0.4619, 0.1976, 0.6302],\n",
       "         [0.2766, 0.0868, 0.3223]],\n",
       "\n",
       "        [[0.3140, 0.2869, 0.3077],\n",
       "         [0.5580, 0.3677, 0.6162],\n",
       "         [0.5029, 0.2807, 0.6335],\n",
       "         [0.5147, 0.2656, 0.6470],\n",
       "         [0.2099, 0.0844, 0.2582],\n",
       "         [0.3140, 0.2869, 0.3077],\n",
       "         [0.5580, 0.3677, 0.6162],\n",
       "         [0.5029, 0.2807, 0.6335],\n",
       "         [0.5147, 0.2656, 0.6470],\n",
       "         [0.2099, 0.0844, 0.2582]],\n",
       "\n",
       "        [[0.3002, 0.2256, 0.3225],\n",
       "         [0.5527, 0.3547, 0.6346],\n",
       "         [0.5101, 0.2954, 0.6192],\n",
       "         [0.5273, 0.2951, 0.6420],\n",
       "         [0.1907, 0.0927, 0.2347],\n",
       "         [0.3002, 0.2256, 0.3225],\n",
       "         [0.5527, 0.3547, 0.6346],\n",
       "         [0.5101, 0.2954, 0.6192],\n",
       "         [0.5273, 0.2951, 0.6420],\n",
       "         [0.1907, 0.0927, 0.2347]],\n",
       "\n",
       "        [[0.2941, 0.1990, 0.3317],\n",
       "         [0.5505, 0.3443, 0.6420],\n",
       "         [0.5141, 0.3043, 0.6149],\n",
       "         [0.5308, 0.3090, 0.6369],\n",
       "         [0.1850, 0.1000, 0.2249],\n",
       "         [0.2941, 0.1990, 0.3317],\n",
       "         [0.5505, 0.3443, 0.6420],\n",
       "         [0.5141, 0.3043, 0.6149],\n",
       "         [0.5308, 0.3090, 0.6369],\n",
       "         [0.1850, 0.1000, 0.2249]],\n",
       "\n",
       "        [[0.2914, 0.1867, 0.3366],\n",
       "         [0.5495, 0.3383, 0.6454],\n",
       "         [0.5159, 0.3088, 0.6132],\n",
       "         [0.5321, 0.3158, 0.6338],\n",
       "         [0.1833, 0.1048, 0.2204],\n",
       "         [0.2914, 0.1867, 0.3366],\n",
       "         [0.5495, 0.3383, 0.6454],\n",
       "         [0.5159, 0.3088, 0.6132],\n",
       "         [0.5321, 0.3158, 0.6338],\n",
       "         [0.1833, 0.1048, 0.2204]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "cpl = ChebyPolyLayer(coefs_ts)\n",
    "cpl(batch.edge_index, batch.edge_weight, batch.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from experiments.cheby_poly_layer import ChebyPolyLayer\n",
    "from experiments.pde_layers import get_cheby_coefs_heat, get_cheby_coefs_wave\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GraphClassifier(nn.Module):\n",
    "    def __init__(self, pde, ts, n_input, n_hidden, n_output, degree=100, c=1., N=1000):\n",
    "        super(GraphClassifier, self).__init__()\n",
    "        self.pde = pde\n",
    "        self.ts = ts\n",
    "        if pde == 'heat':\n",
    "            self.coefs = get_cheby_coefs_heat(ts, degree, c, N)\n",
    "        elif pde == 'wave':\n",
    "            self.coefs = get_cheby_coefs_wave(ts, degree, c, N)\n",
    "        else: raise ValueError('Invalid PDE type!')\n",
    "        self.pde_layer1 = ChebyPolyLayer(self.coefs)\n",
    "        self.lin1 = nn.Linear(n_input, n_hidden)\n",
    "        # self.pde_layer2 = ChebyPolyLayer(self.coefs)\n",
    "        # self.lin2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.pde_layer1(edge_index, edge_weight, x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.pde_layer2(edge_index, edge_weight, x)\n",
    "        # x = self.lin2(x)\n",
    "        # x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0516, 0.5636, 0.0000, 0.0000, 0.0872],\n",
       "         [0.0516, 0.5636, 0.0000, 0.0000, 0.0872]],\n",
       "\n",
       "        [[0.0257, 0.5628, 0.0000, 0.0000, 0.0582],\n",
       "         [0.0257, 0.5628, 0.0000, 0.0000, 0.0582]],\n",
       "\n",
       "        [[0.0151, 0.5624, 0.0000, 0.0000, 0.0569],\n",
       "         [0.0151, 0.5624, 0.0000, 0.0000, 0.0569]],\n",
       "\n",
       "        [[0.0109, 0.5622, 0.0000, 0.0000, 0.0563],\n",
       "         [0.0109, 0.5622, 0.0000, 0.0000, 0.0563]],\n",
       "\n",
       "        [[0.0104, 0.5621, 0.0000, 0.0000, 0.0560],\n",
       "         [0.0104, 0.5621, 0.0000, 0.0000, 0.0560]],\n",
       "\n",
       "        [[0.0103, 0.5620, 0.0000, 0.0000, 0.0558],\n",
       "         [0.0103, 0.5620, 0.0000, 0.0000, 0.0558]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heat_classifer = GraphClassifier('heat', ts, n_input=3, n_hidden=5, n_output=4)\n",
    "heat_classifer(batch.x, batch.edge_index, batch.edge_weight, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
